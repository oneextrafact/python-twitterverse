{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Guido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding Guido\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from tweepy import Client, Paginator, API\n",
    "\n",
    "bearer_token = os.environ.get(\"TWITTER_BEARER_TOKEN\")\n",
    "client = Client(bearer_token)\n",
    "api = API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by looking at the network of Guido van Rossum, creator of Python and former \"Benevolent Dictator for Life\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_response = client.get_user(username=\"gvanrossum\", user_fields=[\"description\", \"location\", \"public_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrive GVR's twitter id, which is required for API calls. We can also look at his public metrics. He has almost 270,000 accounts following him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'followers_count': 268158,\n",
       " 'following_count': 514,\n",
       " 'tweet_count': 3553,\n",
       " 'listed_count': 4702}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvr = user_response[0].id\n",
    "user_response[0].public_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who does Guido Van Rossum follow? Originally I made the mistake of using \"subscriptions\" instead of \"following\", don't do that! He has almost 270K followers. Also, because I find it really confusing to talk about followers and following, I'm going to refer to the accounts that GVR follows as his \"subscriptions\". GVR subscribes to just over 500 acccounts. Conveniently, the user objects from tweepy map very nicely to pandas dataframes. A little pandas magic with json_normalize lets us explode the \"public_metrics\" dictionary into new columns in our frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_subscriptions_df(id):\n",
    "    \"\"\" \n",
    "    Function retrieves subscriptions (accounts that a user is following) for a given user id. \n",
    "    Function uses pagination if the user account has more than 1000 subscriptions, which is the limit \n",
    "    of what the Twitter api will return in one call. \n",
    "    \"\"\"\n",
    "    client = Client(bearer_token=bearer_token)\n",
    "    subscriptions = []\n",
    "    for subscription in Paginator(client.get_users_following, id, user_fields=[\"description\", \"location\", \"public_metrics\"], max_results=1000):\n",
    "        if subscription.data is None:\n",
    "            return None\n",
    "        else:\n",
    "            subscriptions.extend(subscription.data)\n",
    "    subscriptions_df = pd.DataFrame(subscriptions)\n",
    "\n",
    "    \n",
    "    # public metrics is a dictionary containing tweet and follower counts. \n",
    "    # we merge it with the original dataframe. \n",
    "    subscriptions_df = subscriptions_df.merge(\n",
    "        pd.json_normalize(subscriptions_df.public_metrics), left_index=True, right_index=True).\\\n",
    "        drop(\"public_metrics\", axis=\"columns\")\n",
    "    subscriptions_df[\"subscriber\"] = id\n",
    "\n",
    "    return subscriptions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>subscriber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I work @Microsoft, making Python more awesome ...</td>\n",
       "      <td>14076724</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>John Lam</td>\n",
       "      <td>john_lam</td>\n",
       "      <td>4406</td>\n",
       "      <td>586</td>\n",
       "      <td>6182</td>\n",
       "      <td>294</td>\n",
       "      <td>15804774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intl. Relations &amp; MPP Grad üåç noob intersection...</td>\n",
       "      <td>187196955</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Camila Guti√©rrez (she/her)</td>\n",
       "      <td>Mariacamilagl30</td>\n",
       "      <td>695</td>\n",
       "      <td>444</td>\n",
       "      <td>259</td>\n",
       "      <td>9</td>\n",
       "      <td>15804774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creator of @datasetteproj, co-creator Django. ...</td>\n",
       "      <td>12497</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Simon Willison</td>\n",
       "      <td>simonw</td>\n",
       "      <td>41380</td>\n",
       "      <td>5174</td>\n",
       "      <td>41106</td>\n",
       "      <td>1594</td>\n",
       "      <td>15804774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partner Software Architect at Microsoft on .NE...</td>\n",
       "      <td>19481808</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>David Fowler üáßüáßüá∫üá∏</td>\n",
       "      <td>davidfowl</td>\n",
       "      <td>103795</td>\n",
       "      <td>1318</td>\n",
       "      <td>61361</td>\n",
       "      <td>1607</td>\n",
       "      <td>15804774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The #1 Python-focused podcast covering the peo...</td>\n",
       "      <td>3098427092</td>\n",
       "      <td>Portland, OR USA</td>\n",
       "      <td>Talk Python Podcast</td>\n",
       "      <td>TalkPython</td>\n",
       "      <td>61473</td>\n",
       "      <td>4043</td>\n",
       "      <td>6076</td>\n",
       "      <td>1342</td>\n",
       "      <td>15804774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description          id  \\\n",
       "0  I work @Microsoft, making Python more awesome ...    14076724   \n",
       "1  Intl. Relations & MPP Grad üåç noob intersection...   187196955   \n",
       "2  Creator of @datasetteproj, co-creator Django. ...       12497   \n",
       "3  Partner Software Architect at Microsoft on .NE...    19481808   \n",
       "4  The #1 Python-focused podcast covering the peo...  3098427092   \n",
       "\n",
       "            location                        name         username  \\\n",
       "0        Redmond, WA                    John Lam         john_lam   \n",
       "1             Berlin  Camila Guti√©rrez (she/her)  Mariacamilagl30   \n",
       "2  San Francisco, CA              Simon Willison           simonw   \n",
       "3            Redmond           David Fowler üáßüáßüá∫üá∏        davidfowl   \n",
       "4   Portland, OR USA         Talk Python Podcast       TalkPython   \n",
       "\n",
       "   followers_count  following_count  tweet_count  listed_count  subscriber  \n",
       "0             4406              586         6182           294    15804774  \n",
       "1              695              444          259             9    15804774  \n",
       "2            41380             5174        41106          1594    15804774  \n",
       "3           103795             1318        61361          1607    15804774  \n",
       "4            61473             4043         6076          1342    15804774  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvr_subscriptions_df = get_subscriptions_df(gvr)\n",
    "gvr_subscriptions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look around at the accounts that Guido is following. They have a very wide range of \"subscribers\", from 16 to 19,250,000. At the top end, some of the accounts are for celebrities, including: \n",
    "\n",
    "- Edward Snowden\n",
    "- Samantha Power, former US Ambassador to the UN\n",
    "- Dave Matthews\n",
    "- Grant Imahara\n",
    "- Leonard Nimoy\n",
    "\n",
    "We can also see a lot of organizations, such as Meta, BBC Breaking News, the Mars Rover, etc. For both sets of accunts, it is interesting that so many of these accounts have very small subscription counts of their own, though, much more in line with typical people. Al Gore, for instance, has 2.9 million subscribers but is subscribing to just 40 accounts himself. \n",
    "\n",
    "We are interested in the subscriptions for these accounts because if one of them is following GVR back, it's a pretty crucial indicator that they are part of the python universe (though a number of them could be friends or family or insitutions with personal connections). If we find such a person, we're also interested in who they follow because they are likely to be part of the community as well, and it gives us a sense of where they are / what they're interested in in the Python ecosystem. \n",
    "\n",
    "We are left with a problem, though. To find out if someone is following GVR back, we need to get their list of subscriptions This would leave us 508,982 user records to sort through! Even getting that list would be a difficult problem. The twitter api will return a max of 1000 subscriptions per call, and there is a rate limit of 15 calls in 15 minutes. Getting the entire list, then, would take a long time and would need to be babysat constantly. To get under this limit, we will need to take a different approach. As we are looking for the structure of the Python ecosystem, we will focus on GVR's subscriptions that mention Python in their descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_subscriptions_df = gvr_subscriptions_df[gvr_subscriptions_df.description.str.contains(\"ython\")].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with about 100 accounts. Of these connections, about 75% have less than 1000 subscriptions and could be retrieved in one call. We'll start by getting their connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     101.000000\n",
       "mean      685.336634\n",
       "std      1111.875202\n",
       "min         0.000000\n",
       "25%       113.000000\n",
       "50%       311.000000\n",
       "75%       772.000000\n",
       "max      6644.000000\n",
       "Name: following_count, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_subscriptions_df[\"following_count\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by getting \"regular\" users, defined for our purposes as anyone with less than 1000 followers. They are special because we can retrieve their entire subscription list in a single call to the twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_user_ids = python_subscriptions_df.query(\"\"\"following_count <= 1000\"\"\").id.values\n",
    "len(regular_user_ids)\n",
    "subscriptions_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had thought about using a try-catch block here to get the TooManyRequests exception, but I wasn't sure what to do when it happened. The rate limit is a known quantity more than an exception, which means it's better if the code handles it explicitly (respects it) than crashing because it exceeds the limit. If we were going to handle it, it would make sense to do something about it in our get_subscriptions_df function rather than here, as that code would have to handle a situation where an account has more than 1000 followers and the call has to be paginated. I have included logic for recovery, though - any successful call gets added to a list of processed ids. If we have to make the call again, we will only do so for users that we have not yet processed. The outer loop makes 15 calls at a time to make sure we stay under the twitter rate limit. At each execution of the for loop, we sleep for 930 seconds.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39 to 54 of 83\n",
      "Processing 54 to 69 of 83\n",
      "Processing 69 to 84 of 83\n"
     ]
    }
   ],
   "source": [
    "from tweepy.errors import TooManyRequests\n",
    "\n",
    "from time import sleep\n",
    "processed_ids = []\n",
    "\n",
    "for i in range(len(subscriptions_frames), len(regular_user_ids), 15):\n",
    "    print(f\"Processing {i} to {i+15} of {len(regular_user_ids)}\")\n",
    "    for user_id in regular_user_ids[i:i+15]:\n",
    "        user_subscriptions_df = get_subscriptions_df(user_id)\n",
    "        if user_subscriptions_df is not None:\n",
    "            subscriptions_frames.append(user_subscriptions_df)\n",
    "        processed_ids.append(user_id)\n",
    "    # sleep 15 minutes (+30s to be careful) so we don't exceed the rate limit\n",
    "    sleep(930)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the results of our calls and save the work so we can resume from this point if we have to reload the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(subscriptions_frames).to_parquet(\"light_subscribers.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining accounts present an interesting intellectual problem / pain in the butt. Given pagination limits and rate limits, if we want to process accounts that follow more than 1000 we would have to solve something called \"the knapsack problem\". That is, we would have to make sure that we were not requesting more than 15000 subscriptions in any given round of cals. As there are only 18 such individuals, I'll take the hit of waiting 15 minutes after each call, despite the inefficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_subscriber_userids = python_subscriptions_df.query(\"\"\"following_count > 1000\"\"\").id.values\n",
    "heavy_subscribers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userid in heavy_subscriber_userids:\n",
    "    subscriptions = get_subscriptions_df(user_id)\n",
    "    if subscriptions is not None:\n",
    "        heavy_subscribers.append(subscriptions)\n",
    "    sleep(900)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our work here as well to make sure we don't have to do this again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(heavy_subscribers).to_parquet(\"heavy_subscribers.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can concatenate both sets of data and save it as a single frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.concat(subscriptions_frames), pd.concat(heavy_subscribers)]).to_parquet(\"gvr_subscribers.parquet\")\n",
    "subscriptions_df = pd.concat([pd.concat(subscriptions_frames), pd.concat(heavy_subscribers)])\n",
    "subscriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to remember to add back GVR's own subscriptions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers_with_gvr_df = pd.concat([subscriptions_df, gvr_subscriptions_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 30000 subscriptions in our fledgling network for about 17000 individuals and 80 seeds. Time to bring in networkx!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "python_twitterverse = nx.from_pandas_edgelist(subscribers_with_gvr_df, source=\"subscriber\", target=\"id\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought it would be nice to bring in the user attributes to associate with each node. I thought that would be as simple as removing our \"subscriber\" field from the subscriptions dataframe and dropping duplicates.  I had a surprise, though - in between my calls, the public metrics of certain users changed! This highlights the really dynamic nature of Twitter and is a cautionary tale about thinking it is possible to have a truly complete sense of the Python (or any) twitterverse, even with infinite computing power and no rate limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25928667</td>\n",
       "      <td>12</td>\n",
       "      <td>4146</td>\n",
       "      <td>19997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25928668</td>\n",
       "      <td>12</td>\n",
       "      <td>4146</td>\n",
       "      <td>19997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25929994</td>\n",
       "      <td>12</td>\n",
       "      <td>4146</td>\n",
       "      <td>19997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25934541</td>\n",
       "      <td>12</td>\n",
       "      <td>4148</td>\n",
       "      <td>20003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25932578</td>\n",
       "      <td>12</td>\n",
       "      <td>4148</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>46th President of the United States, husband t...</td>\n",
       "      <td>1349149096909668363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>President Biden</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>25932599</td>\n",
       "      <td>12</td>\n",
       "      <td>4148</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description                   id  \\\n",
       "114  46th President of the United States, husband t...  1349149096909668363   \n",
       "4    46th President of the United States, husband t...  1349149096909668363   \n",
       "27   46th President of the United States, husband t...  1349149096909668363   \n",
       "198  46th President of the United States, husband t...  1349149096909668363   \n",
       "33   46th President of the United States, husband t...  1349149096909668363   \n",
       "114  46th President of the United States, husband t...  1349149096909668363   \n",
       "\n",
       "    location             name username  followers_count  following_count  \\\n",
       "114      NaN  President Biden    POTUS         25928667               12   \n",
       "4        NaN  President Biden    POTUS         25928668               12   \n",
       "27       NaN  President Biden    POTUS         25929994               12   \n",
       "198      NaN  President Biden    POTUS         25934541               12   \n",
       "33       NaN  President Biden    POTUS         25932578               12   \n",
       "114      NaN  President Biden    POTUS         25932599               12   \n",
       "\n",
       "     tweet_count  listed_count  \n",
       "114         4146         19997  \n",
       "4           4146         19997  \n",
       "27          4146         19997  \n",
       "198         4148         20003  \n",
       "33          4148         20000  \n",
       "114         4148         20000  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = subscriptions_df.drop(\"subscriber\", axis=\"columns\").drop_duplicates().copy()\n",
    "users_df[users_df.id==users_df[users_df.id.duplicated()].id.values[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop duplicates based on the id column only, then set the index for the frame to id. This lets us make a dictionary mapping user ids to their attributes, which is what networkx needs from us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.drop_duplicates(subset=[\"id\"], keep=\"last\")\n",
    "users_df = users_df.set_index(\"id\")\n",
    "users_df = users_df.fillna(\"Not Provided\")\n",
    "users_dict = users_df.to_dict(orient=\"index\")\n",
    "id2user_dict = users_df[\"username\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set attributes for our nodes. We also relabel them to use the usernames instead of ids, which will make our graph a little easier to play with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f8c67c23a00>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enhance nodes by adding user details\n",
    "\n",
    "nx.set_node_attributes(python_twitterverse, users_dict)\n",
    "nx.relabel_nodes(python_twitterverse, users_df[\"username\"].to_dict(), copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the network to a common graph file format, graphml. This can be read by networkx and also by other useful tools such as Gephi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(python_twitterverse, \"gvr_twitterverse.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
